{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import jieba\n",
    "import jieba.posseg as psg\n",
    "from gensim import corpora, models\n",
    "from jieba import analyse\n",
    "import functools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108295 entries, 0 to 108294\n",
      "Data columns (total 3 columns):\n",
      "id       108295 non-null object\n",
      "title    108295 non-null object\n",
      "text     108295 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.5+ MB\n",
      "None\n",
      "        id                title  \\\n",
      "0  D000001   林志颖老婆深夜敷面膜，睫毛太长好吓人   \n",
      "1  D000002   小s夸杨幂身材好，杨幂回复太精彩了！   \n",
      "2  D000003    年轻时的她风华绝代，现却无人送祝福   \n",
      "3  D000004   林心如屡曝霍建华私生活被怼蹭老公人气   \n",
      "4  D000005  曾是TVB颜值担当，近照曝光发现真老了   \n",
      "\n",
      "                                                text  \n",
      "0  早年林志颖带kimi上《爸爸去哪儿》的时候，当时遮遮掩掩的林志颖老婆低调探班，总让人觉得格外...  \n",
      "1  翩若惊鸿，婉若游龙。曹植形容洛神的这两句，实在太抽象，以至于始终寻不到承受对象。直到在《大军...  \n",
      "2  上个世纪香港影视界涌现出了不少高颜值女星，在《大话西游之月光宝盒》中饰演春三十娘和蜘蛛精的蓝...  \n",
      "3  霍建华林心如1905电影网讯近日，林心如在接受采访时爆料称老公霍建华会主动向女儿索吻，笑称他...  \n",
      "4  不知道有多少人是看TVB剧集长大的，小时候我每一天晚上都会守着电视看TVB剧集的。可以说对于...  \n"
     ]
    }
   ],
   "source": [
    "all_docs_df = pd.read_csv('../../data/chusai/all_docs.txt', sep='\\001', header=None)\n",
    "all_docs_df.columns = ['id', 'title', 'text']\n",
    "all_docs_df['title'] = all_docs_df['title'].astype(str)\n",
    "all_docs_df['text'] = all_docs_df['text'].astype(str)\n",
    "print(all_docs_df.info())\n",
    "print(all_docs_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.152 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                title  \\\n",
      "0  D000001   林志颖老婆深夜敷面膜，睫毛太长好吓人   \n",
      "1  D000002   小s夸杨幂身材好，杨幂回复太精彩了！   \n",
      "2  D000003    年轻时的她风华绝代，现却无人送祝福   \n",
      "3  D000004   林心如屡曝霍建华私生活被怼蹭老公人气   \n",
      "4  D000005  曾是TVB颜值担当，近照曝光发现真老了   \n",
      "\n",
      "                                                text  \\\n",
      "0  早年林志颖带kimi上《爸爸去哪儿》的时候，当时遮遮掩掩的林志颖老婆低调探班，总让人觉得格外...   \n",
      "1  翩若惊鸿，婉若游龙。曹植形容洛神的这两句，实在太抽象，以至于始终寻不到承受对象。直到在《大军...   \n",
      "2  上个世纪香港影视界涌现出了不少高颜值女星，在《大话西游之月光宝盒》中饰演春三十娘和蜘蛛精的蓝...   \n",
      "3  霍建华林心如1905电影网讯近日，林心如在接受采访时爆料称老公霍建华会主动向女儿索吻，笑称他...   \n",
      "4  不知道有多少人是看TVB剧集长大的，小时候我每一天晚上都会守着电视看TVB剧集的。可以说对于...   \n",
      "\n",
      "                      title_list  \\\n",
      "0  [林志颖, 老婆, 深夜, 面膜, 睫毛, 太长, 吓人]   \n",
      "1          [夸杨, 身材, 杨幂, 回复, 太精彩]   \n",
      "2            [年轻, 风华绝代, 无人, 送祝福]   \n",
      "3     [林心如, 曝霍, 建华, 私生活, 老公, 人气]   \n",
      "4     [TVB, 颜值, 担当, 照曝光, 发现, 真老]   \n",
      "\n",
      "                                           text_list  \\\n",
      "0  [早年, 林志颖, kimi, 爸爸, 当时, 遮遮掩掩, 林志颖, 老婆, 低调, 探班,...   \n",
      "1  [翩若惊鸿, 婉若游龙, 曹植, 形容, 洛神, 两句, 实在, 抽象, 始终, 不到, 承...   \n",
      "2  [上个世纪, 香港, 影视界, 涌现出, 不少, 高颜值, 女星, 大话西游, 月光宝盒, ...   \n",
      "3  [建华, 林心如, 1905, 电影, 网讯, 近日, 林心如, 接受, 采访, 爆料, 老...   \n",
      "4  [知道, TVB, 剧集, 长大, 小时候, 一天, 晚上, 电视, TVB, 剧集, 时期...   \n",
      "\n",
      "                                          title_text  \\\n",
      "0  林志颖老婆深夜敷面膜，睫毛太长好吓人。早年林志颖带kimi上《爸爸去哪儿》的时候，当时遮遮掩...   \n",
      "1  小s夸杨幂身材好，杨幂回复太精彩了！。翩若惊鸿，婉若游龙。曹植形容洛神的这两句，实在太抽象，...   \n",
      "2  年轻时的她风华绝代，现却无人送祝福。上个世纪香港影视界涌现出了不少高颜值女星，在《大话西游之...   \n",
      "3  林心如屡曝霍建华私生活被怼蹭老公人气。霍建华林心如1905电影网讯近日，林心如在接受采访时爆...   \n",
      "4  曾是TVB颜值担当，近照曝光发现真老了。不知道有多少人是看TVB剧集长大的，小时候我每一天晚...   \n",
      "\n",
      "                                     title_text_list  \n",
      "0  [林志颖, 老婆, 深夜, 面膜, 睫毛, 太长, 吓人, 早年, 林志颖, kimi, 爸...  \n",
      "1  [夸杨, 身材, 杨幂, 回复, 太精彩, 翩若惊鸿, 婉若游龙, 曹植, 形容, 洛神, ...  \n",
      "2  [年轻, 风华绝代, 无人, 送祝福, 上个世纪, 香港, 影视界, 涌现出, 不少, 高颜...  \n",
      "3  [林心如, 曝霍, 建华, 私生活, 老公, 人气, 建华, 林心如, 1905, 电影, ...  \n",
      "4  [TVB, 颜值, 担当, 照曝光, 发现, 真老, 知道, TVB, 剧集, 长大, 小时...  \n"
     ]
    }
   ],
   "source": [
    "#停用词表加载方法\n",
    "def get_stopword_list():\n",
    "    #停用词表存储路径，每一行为一个词，按行读取进行加载\n",
    "    #进行编码转换确保匹配准确率\n",
    "    stop_word_path = '../stopword.txt'\n",
    "    stop_word_list = [sw.replace('\\n', '') for sw in open(stop_word_path).readlines()]\n",
    "    return stop_word_list\n",
    "\n",
    "#分词方法，调用结巴接口\n",
    "def seg_to_list(sentence, pos=False):\n",
    "    if not pos:\n",
    "        #不进行词性标注的分词方法\n",
    "        seg_list = jieba.cut(sentence)\n",
    "    else:\n",
    "        #进行词性标注的分词方法\n",
    "        seg_list = psg.cut(sentence)\n",
    "    return seg_list\n",
    "\n",
    "#去除干扰词\n",
    "def word_filter(seg_list, stopword_list, pos=False):\n",
    "    \n",
    "    filter_list = []\n",
    "    #根据pos参数选择是否词性过滤\n",
    "    #不进行词性过滤，则将词性都标记为n，表示全部保留\n",
    "    for seg in seg_list:\n",
    "        if not pos:\n",
    "            word = seg\n",
    "            flag = 'n'\n",
    "        else:\n",
    "            word = seg.word\n",
    "            flag = seg.flag\n",
    "        if not flag.startswith('n'):\n",
    "            continue\n",
    "        #过滤高停用词表中的词，以及长度为<2的词\n",
    "        if not word in stopword_list and len(word) > 1:\n",
    "            filter_list.append(word)\n",
    "    \n",
    "    return filter_list\n",
    "\n",
    "def jieba_word_deal(sentence, stopword_list, pos=False):\n",
    "    #调用上面方式对数据集进行处理，处理后的每条数据仅保留非干扰词\n",
    "    seg_list = seg_to_list(sentence, pos)\n",
    "    filter_list = word_filter(seg_list, stopword_list, pos)\n",
    "    return filter_list\n",
    "\n",
    "stopword_list = get_stopword_list()\n",
    "all_docs_df['title_list'] = all_docs_df['title'].map(lambda x : jieba_word_deal(x, stopword_list, False))\n",
    "all_docs_df['text_list'] = all_docs_df['text'].map(lambda x : jieba_word_deal(x, stopword_list, False))\n",
    "all_docs_df['title_text'] = all_docs_df['title'] + '。' + all_docs_df['text']\n",
    "all_docs_df['title_text_list'] = all_docs_df['title_text'].map(lambda x : jieba_word_deal(x, stopword_list, False))\n",
    "print(all_docs_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#排序函数，用于topK关键词的按值排\n",
    "def cmp(e1, e2):\n",
    "    res = np.sign(e1[1] - e2[1])\n",
    "    if res != 0:\n",
    "        return res\n",
    "    else:\n",
    "        a = e1[0] + e2[0]\n",
    "        b = e2[0] + e1[0]\n",
    "        if a > b:\n",
    "            return 1\n",
    "        elif a == b:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 主题模型\n",
    "class TopicModel(object):\n",
    "    # 三个传入参数：处理后的数据集，关键词数量，具体模型（LSI、LDA），主题数量\n",
    "    def __init__(self, doc_list, keyword_num, model='LSI', num_topics=10):\n",
    "        # 使用gensim的接口，将文本转为向量化表示\n",
    "        # 先构建词空间\n",
    "        self.dictionary = corpora.Dictionary(doc_list)\n",
    "        # 使用BOW模型向量化\n",
    "        corpus = [self.dictionary.doc2bow(doc) for doc in doc_list]\n",
    "        # 对每个词，根据tf-idf进行加权，得到加权后的向量表示\n",
    "        self.tfidf_model = models.TfidfModel(corpus)\n",
    "        self.corpus_tfidf = self.tfidf_model[corpus]\n",
    "\n",
    "        self.keyword_num = keyword_num\n",
    "        self.num_topics = num_topics\n",
    "        # 选择加载的模型\n",
    "        if model == 'LSI':\n",
    "            self.model = self.train_lsi()\n",
    "        else:\n",
    "            self.model = self.train_lda()\n",
    "\n",
    "        # 得到数据集的主题-词分布\n",
    "        word_dic = self.word_dictionary(doc_list)\n",
    "        self.wordtopic_dic = self.get_wordtopic(word_dic)\n",
    "\n",
    "    def train_lsi(self):\n",
    "        lsi = models.LsiModel(self.corpus_tfidf, id2word=self.dictionary, num_topics=self.num_topics)\n",
    "        return lsi\n",
    "\n",
    "    def train_lda(self):\n",
    "        lda = models.LdaModel(self.corpus_tfidf, id2word=self.dictionary, num_topics=self.num_topics)\n",
    "        return lda\n",
    "\n",
    "    def get_wordtopic(self, word_dic):\n",
    "        wordtopic_dic = {}\n",
    "\n",
    "        for word in word_dic:\n",
    "            single_list = [word]\n",
    "            wordcorpus = self.tfidf_model[self.dictionary.doc2bow(single_list)]\n",
    "            wordtopic = self.model[wordcorpus]\n",
    "            wordtopic_dic[word] = wordtopic\n",
    "        return wordtopic_dic\n",
    "\n",
    "    # 计算词的分布和文档的分布的相似度，取相似度最高的keyword_num个词作为关键词\n",
    "    def get_simword(self, word_list):\n",
    "        sentcorpus = self.tfidf_model[self.dictionary.doc2bow(word_list)]\n",
    "        senttopic = self.model[sentcorpus]\n",
    "\n",
    "        # 余弦相似度计算\n",
    "        def calsim(l1, l2):\n",
    "            a, b, c = 0.0, 0.0, 0.0\n",
    "            for t1, t2 in zip(l1, l2):\n",
    "                x1 = t1[1]\n",
    "                x2 = t2[1]\n",
    "                a += x1 * x1\n",
    "                b += x1 * x1\n",
    "                c += x2 * x2\n",
    "            sim = a / math.sqrt(b * c) if not (b * c) == 0.0 else 0.0\n",
    "            return sim\n",
    "\n",
    "        # 计算输入文本和每个词的主题分布相似度\n",
    "        sim_dic = {}\n",
    "        for k, v in self.wordtopic_dic.items():\n",
    "            if k not in word_list:\n",
    "                continue\n",
    "            sim = calsim(v, senttopic)\n",
    "            sim_dic[k] = sim\n",
    "        \n",
    "        result_dict = {}\n",
    "        for k, v in sorted(sim_dic.items(), key=functools.cmp_to_key(cmp), reverse=True)[:self.keyword_num]:\n",
    "            result_dict[k] = result_dict.get(k, 0.0) + float(v)\n",
    "        return result_dict\n",
    "        \n",
    "    # 词空间构建方法和向量化方法，在没有gensim接口时的一般处理方法\n",
    "    def word_dictionary(self, doc_list):\n",
    "        dictionary = []\n",
    "        for doc in doc_list:\n",
    "            dictionary.extend(doc)\n",
    "\n",
    "        dictionary = list(set(dictionary))\n",
    "\n",
    "        return dictionary\n",
    "\n",
    "    def doc2bowvec(self, word_list):\n",
    "        vec_list = [1 if word in word_list else 0 for word in self.dictionary]\n",
    "        return vec_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_lsi_model = TopicModel(all_docs_df['title_text_list'], 5, 'LSI')\n",
    "all_docs_df['result_lsi_dict'] = all_docs_df['title_text_list'].map(lambda x: topic_lsi_model.get_simword(x))\n",
    "print(all_docs_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_lda_model = TopicModel(all_docs_df['title_text_list'], 5, 'LDA')\n",
    "all_docs_df['result_lda_dict'] = all_docs_df['title_text_list'].map(lambda x: topic_lda_model.get_simword(x))\n",
    "print(all_docs_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv('../../result/chusai/sample.csv', encoding='ISO-8859-1')\n",
    "print(len(sample_df))\n",
    "sample_df = pd.merge(sample_df, all_docs_df, on='id', how='left')\n",
    "print(sample_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_n_word(result_dict, n):\n",
    "    keys = list(result_dict.keys())\n",
    "    if len(keys) < n:\n",
    "        return ''\n",
    "    else:\n",
    "        return keys[n - 1]\n",
    "    \n",
    "# 导出预测结果\n",
    "def exportResult(df, fileName, model):\n",
    "    if model == 'LSI':\n",
    "        df['label1'] = df['result_lsi_dict'].map(lambda x: get_top_n_word(x, 1))\n",
    "        df['label2'] = df['result_lsi_dict'].map(lambda x: get_top_n_word(x, 2))\n",
    "    else:\n",
    "        df['label1'] = df['result_lda_dict'].map(lambda x: get_top_n_word(x, 1))\n",
    "        df['label2'] = df['result_lda_dict'].map(lambda x: get_top_n_word(x, 2))\n",
    "    print(df.head())\n",
    "    df[['id', 'label1', 'label2']].to_csv('../../result/chusai/%s.csv' % fileName, header=True, index=False)\n",
    "    \n",
    "exportResult(sample_df, 'topic_lsi_baseline_9_3_4', 'LSI')\n",
    "exportResult(sample_df, 'topic_lda_baseline_9_3_5', 'LDA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
